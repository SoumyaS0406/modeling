{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rhea\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import edward as ed\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from edward.models import Bernoulli, MultivariateNormalTriL, Normal\n",
    "from edward.util import rbf\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split,cross_val_score,KFold\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.preprocessing import StandardScaler,QuantileTransformer\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ed.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"C:\\\\Users\\\\Rhea\\\\Documents\\\\Bayesian Modeling\\\\Datasets\\\\BreastCancerWisconsin\\\\breast-cancer-wisconsin.data\",\n",
    "names=['id','diagnosis','radius_mean','texture_mean','perimeter_mean','area_mean','smoothness_mean','compactness_mean','concavity_mean',\n",
    "       'concave_points_mean','symmetry_mean','fractal_dimension_mean','radius_se','texture_se','perimeter_se','area_se','smoothness_se',\n",
    "       'compactness_se','concavity_se','concave_points_se','symmetry_se','fractal_dimension_se','radius_worst','texture_worst',\n",
    "       'perimeter_worst','area_worst','smoothness_worst','compactness_worst','concavity_worst','concave_points_worst',\n",
    "       'symmetry_worst','fractal_dimension_worst'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "B    357\n",
       "M    212\n",
       "Name: diagnosis, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['diagnosis'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert relevant columns to categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def change_to_category(df):\n",
    "    i=0;\n",
    "    while i<df.columns.size:\n",
    "        if ((df.dtypes[df.columns[i]] == 'object' or df.dtypes[df.columns[i]] == 'bool')):\n",
    "            col = df.dtypes.index[i]\n",
    "            df[col] = df[col].astype('category')\n",
    "        i = i+1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate X and y variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generateXY(df,target_col,var_list):\n",
    "    X=df[varToUse]\n",
    "    y=df[target_col]\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we aim to classify patients as having Malignant and Benign tumor, we decide **'diagnosis'** to be our target variable.\n",
    "<br>\n",
    "Also, we replace 'M' with 1 and 'B' with 0, in the column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data['diagnosis'] = data['diagnosis'].replace('M', 1)\n",
    "# data['diagnosis'] = data['diagnosis'].replace('B', 0)\n",
    "data['diagnosis'] = data['diagnosis'].map({'M':1,'B':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert columns with binary values to categorical\n",
    "change_to_category(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.diagnosis.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'diagnosis', 'radius_mean', 'texture_mean', 'perimeter_mean',\n",
       "       'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean',\n",
       "       'concave_points_mean', 'symmetry_mean', 'fractal_dimension_mean',\n",
       "       'radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se',\n",
       "       'compactness_se', 'concavity_se', 'concave_points_se', 'symmetry_se',\n",
       "       'fractal_dimension_se', 'radius_worst', 'texture_worst',\n",
       "       'perimeter_worst', 'area_worst', 'smoothness_worst',\n",
       "       'compactness_worst', 'concavity_worst', 'concave_points_worst',\n",
       "       'symmetry_worst', 'fractal_dimension_worst'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#drop irrelevant columns\n",
    "data.drop(['id'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 31)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2 = pd.get_dummies(data)\n",
    "data2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create training and testing vars\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(data, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Indeppendent and Dependent features\n",
    "target_col='diagnosis'\n",
    "varToUse=data.columns.tolist()\n",
    "varToUse.remove('diagnosis')\n",
    "\n",
    "\n",
    "Train_X,Train_Y = generateXY(train,target_col,varToUse)\n",
    "Test_X,Test_Y = generateXY(test,target_col,varToUse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Support Vector Machines\n",
      "Train Precision = 0.9517273576097105\n",
      "Train Recall = 0.9102941176470589\n",
      "Train F1 Score  = 0.9285341350616495\n",
      "Accuracy score  = 0.9490206411945541\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "    print (\"Model: Support Vector Machines\")\n",
    "svm_clf = svm.SVC(kernel='linear', C = 1.0)\n",
    "\n",
    "precision_svm = cross_val_score(svm_clf, Train_X, Train_Y, cv=10, scoring='precision')\n",
    "print (\"Train Precision = {}\".format(precision_svm.mean()))\n",
    "recall_svm = cross_val_score(svm_clf, Train_X, Train_Y, cv=10, scoring='recall')\n",
    "print (\"Train Recall = {}\".format(recall_svm.mean()))\n",
    "f1score_svm = cross_val_score(svm_clf, Train_X, Train_Y, cv=10, scoring='f1')\n",
    "print (\"Train F1 Score  = {}\".format(f1score_svm.mean()))\n",
    "accscore_svm = cross_val_score(svm_clf, Train_X, Train_Y, cv=10, scoring='accuracy', n_jobs=-1)\n",
    "print (\"Accuracy score  = {}\".format(accscore_svm.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_clf.fit(X=Train_X,y=Train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred_svm=svm_clf.predict(Test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.99      0.97        71\n",
      "          1       0.97      0.91      0.94        43\n",
      "\n",
      "avg / total       0.96      0.96      0.96       114\n",
      "\n",
      "confusion matrix\n",
      "[[70  1]\n",
      " [ 4 39]]\n",
      "accuracy score\n",
      "0.956140350877\n"
     ]
    }
   ],
   "source": [
    "svm_report=sklearn.metrics.classification_report(Test_Y,y_pred_svm)\n",
    "print(svm_report)\n",
    "print(\"confusion matrix\")\n",
    "print(confusion_matrix(Test_Y, y_pred_svm))\n",
    "print(\"accuracy score\")\n",
    "print(accuracy_score(Test_Y, y_pred_svm, normalize=True, sample_weight=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x = data2.iloc[0:,1:].as_matrix().astype(np.float32)\n",
    "data_y = data2.iloc[0:,0:1].as_matrix().astype(np.float32)\n",
    "\n",
    "N = 300\n",
    "train_x, test_x = data_x[:N], data_x[N:]\n",
    "train_y, test_y = data_y[:N], data_y[N:]\n",
    "\n",
    "in_size = train_x.shape[1]\n",
    "out_size = train_y.shape[1]\n",
    "\n",
    "N = train_x.shape[0]  # number of data points\n",
    "D = train_x.shape[1]  # number of features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data points in train: 300\n",
      "Number of features in train: 30\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of data points in train: {}\".format(N))\n",
    "print(\"Number of features in train: {}\".format(D))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, [N, D])\n",
    "f = MultivariateNormalTriL(loc=tf.zeros(N), scale_tril=tf.cholesky(rbf(X)))\n",
    "y = Bernoulli(logits=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "qf = Normal(loc=tf.get_variable(\"qf/loc\", [N]),\n",
    "            scale=tf.nn.softplus(tf.get_variable(\"qf/scale\", [N])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 1)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000/5000 [100%] ██████████████████████████████ Elapsed: 54s | Loss: 0.165\n"
     ]
    }
   ],
   "source": [
    "inference = ed.KLqp({f: qf}, data={X: train_x})\n",
    "inference.run(n_iter=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
